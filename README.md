# ğŸ“Š Comparison of RNN vs LSTM vs GRU on IMDB Reviews Sentiment Analysis

## ğŸ§  Project Description

This project presents a comprehensive **comparison of RNN, LSTM, and GRU** architectures for **sentiment analysis** on the **IMDB movie reviews dataset**. The aim is to evaluate how these different recurrent models perform in terms of **accuracy**, **training time**, and **efficiency** when applied to natural language processing (NLP) tasks.

Each model is trained using TensorFlow/Keras with a standardized preprocessing pipeline including **tokenization**, **padding**, and **embedding layers**. The results are visualized using **matplotlib** to highlight performance trade-offs.

---

## ğŸš€ Technologies Used

- ğŸ Python  
- ğŸ” TensorFlow & Keras (RNN, LSTM, GRU)  
- ğŸ’¬ NLP (Tokenization, Padding, Embedding)  
- ğŸ“Š Matplotlib  
- ğŸ—ƒï¸ IMDB Movie Reviews Dataset

---

## ğŸ“‚ Features

- End-to-end pipeline for training and evaluating RNN-based models.
- Preprocessing using Keras `Tokenizer`, padding sequences, and embedding layers.
- Model training using:
  - Vanilla **RNN**
  - Long Short-Term Memory (**LSTM**)
  - Gated Recurrent Unit (**GRU**)
- Evaluation on:
  - Test Accuracy
  - Training Time
- Comparison visualization through **bar graphs and summary tables**.

---

## ğŸ“ˆ Results Summary

| Model | Accuracy | Training Time |
|-------|----------|---------------|
| RNN   | ~X.XX%   | XX seconds    |
| LSTM  | ~X.XX%   | XX seconds    |
| GRU   | ~X.XX%   | XX seconds    |

_(Replace with your actual results)_

---

## ğŸ“Š Visualizations

All model comparisons are shown using:
- Bar plots for accuracy and training time
- Summary table for clear performance analysis

---

## ğŸ› ï¸ How to Run

1. Clone the repository or open the notebook in Google Colab.
2. Install required dependencies:
   ```bash
   pip install tensorflow matplotlib
